# TP6 : Optimisation des Hyperparam√®tres avec Optuna (YOLO tiny)

Ce projet est la r√©alisation du TP6 du cours MLOps. Il vise √† industrialiser l'optimisation des hyperparam√®tres d'un mod√®le de vision par ordinateur (YOLOv8 tiny) en utilisant **Optuna** pour la recherche et **MLflow** pour le tracking des exp√©riences.

---

## üèóÔ∏è Architecture Technique

*   **Mod√®le** : YOLOv8 tiny (`ultralytics`)
*   **Dataset** : Tiny COCO (personnes uniquement), versionn√© avec **DVC**
*   **Tracking** : **MLflow** (Exp√©riences, Param√®tres, M√©triques)
*   **Stockage Artefacts** : **MinIO** (Compatible AWS S3)
*   **Optimisation** : **Optuna** (TPE - Tree-structured Parzen Estimator)
*   **Infrastructure** : Docker Compose

---

## üöÄ Installation et D√©marrage

### 1. Pr√©requis
*   Docker & Docker Compose
*   Python 3.8+
*   Git

### 2. D√©marrage des Services
Lancer la stack MLflow + MinIO :
```bash
docker compose up -d
```
*   **MLflow UI** : http://localhost:5000
*   **MinIO Console** : http://localhost:9001 (User: `minio`, Pass: `minio12345`)

### 3. Configuration de l'Environnement Python
```bash
# Windows PowerShell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

### 4. Configuration des Variables d'Environnement
Pour que le script Python local puisse communiquer avec MinIO et MLflow :

```powershell
# Windows PowerShell
$env:MLFLOW_TRACKING_URI = "http://localhost:5000"
$env:MLFLOW_S3_ENDPOINT_URL = "http://localhost:9000"
$env:AWS_ACCESS_KEY_ID = "minio"
$env:AWS_SECRET_ACCESS_KEY = "minio12345"
```

---

## üèÉ‚Äç‚ôÇÔ∏è Ex√©cution des Exp√©riences

### 1. Run Baseline
Lancon un entra√Ænement simple pour valider la pipeline :
```bash
python -m src.train_cv --epochs 3 --imgsz 320 --exp-name yolo_baseline
```

### 2. Grid Search (Approche Na√Øve)
Lancement d'une grille pr√©d√©finie d'hyperparam√®tres :
```powershell
.\scripts\run_grid.ps1
```

### 3. Optuna Search (Approche Avanc√©e)
Lancement de l'optimisation bay√©sienne avec Optuna :
```powershell
.\scripts\run_optuna.ps1 --n-trials 5
```

---

## üìä Rapport de D√©cision (Compte Rendu)

### 1. Contexte
*   **Objectif** : Maximiser la pr√©cision de d√©tection des personnes sur le dataset Tiny COCO.
*   **Mod√®le** : YOLOv8n (Nano), choisi pour sa rapidit√© d'inf√©rence.
*   **M√©trique Cible** : `metrics/mAP50(B)` (Mean Average Precision √† IoU 0.5).

![Baseline Run](img/baseline-optuna.png)
*Fig 1. Run Baseline initial dans MLflow*

### 2. R√©sum√© des Exp√©riences Optuna
Une √©tude de 5 essais (trials) a √©t√© men√©e pour optimiser deux hyperparam√®tres cl√©s : `epochs` (2 √† 5) et `imgsz` (320 √† 416).

| Trial ID | Epochs | Imgsz | mAP50 (Score) | Statut |
|----------|--------|-------|---------------|--------|
| Trial 0  | 2      | 320   | 0.150         | ‚úÖ      |
| Trial 1  | 3      | 320   | 0.146         | ‚úÖ      |
| Trial 2  | 4      | 320   | 0.155         | ‚úÖ      |
| Trial 3  | 3      | 416   | 0.151         | ‚úÖ      |
| **Trial 4** | **5**      | **320**   | **0.168**         | **üèÜ Best** |

### 3. Analyse et Comparaison

#### Grid Search "Manuelle"
![Grid Search Results](img/compare-without-optuna.png)
*Fig 2. R√©sultats des runs "Grid Search" classique. On observe des performances vari√©es mais sans strat√©gie de convergence.*

#### Comparaison Optuna vs Grid
*   **Impact des Epochs** : On observe une corr√©lation claire entre le nombre d'epochs et la performance. Passer de 2 √† 5 epochs a permis de gagner pr√®s de 1.8 points de mAP (0.150 -> 0.168). Le mod√®le est encore en phase d'apprentissage et ne sature pas √† 5 epochs.
*   **Impact de la Taille d'Image (imgsz)** : Contre-intuitivement, augmenter la taille de 320 √† 416 (Trial 1 vs Trial 3) n'a pas apport√© de gain significatif (0.146 vs 0.151) pour ce faible nombre d'epochs, tout en augmentant le temps de calcul.
*   **Optuna vs Grid Search** : Optuna a rapidement converg√© vers la borne sup√©rieure des epochs d√©finis (5), identifiant efficacement la zone prometteuse sans avoir besoin de tester toutes les combinaisons inefficaces.

![Comparison With Optuna](img/compare-with_optuna.png)
*Fig 3. Vue comparative incluant les runs Optuna (en bleu/vert), montrant l'exploration des hyperparam√®tres.*

### 4. D√©cision pour le Staging
Nous recommandons de promouvoir les hyperparam√®tres du **Trial 4** pour l'environnement de Staging.

*   **Configuration Retenue** :
    *   `epochs`: **5** (ou plus si le budget temps le permet)
    *   `imgsz`: **320** (Suffisant et plus rapide que 416)
*   **Performance Attendue** : mAP50 ‚âà **0.168**

### 5. Discussion : L'apport d'Optuna en MLOps
L'int√©gration d'Optuna pr√©sente plusieurs avantages strat√©giques pour notre pipeline MLOps :
1.  **Efficacit√©** : Contrairement √† une Grid Search qui "aveugl√©ment" teste tout, Optuna (via TPE) apprend des essais pr√©c√©dents pour ne tester que les zones prometteuses, √©conomisant des ressources GPU pr√©cieuses.
2.  **Automatisation** : Le processus est enti√®rement automatis√©. Un ing√©nieur peut lancer une √©tude le soir et r√©cup√©rer les meilleurs param√®tres le matin sans intervention manuelle.
3.  **Tracking Unifi√©** : Gr√¢ce √† l'int√©gration avec MLflow, chaque essai est trac√©, reproductible et comparable, assurant une tra√ßabilit√© totale du cycle de vie du mod√®le.

